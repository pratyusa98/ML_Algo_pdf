{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Before Deep Dive in to deep learning first see some important terminology regarding this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. What are Neural networks?\n",
    "\n",
    "- Neural networks are set of algorithms inspired by the functioning of human brian. Generally when you open your eyes, what you see is called data and is processed by the Nuerons(data processing cells) in your brain, and recognises what is around you. Thatâ€™s how similar the Neural Networks works. They takes a large set of data, process the data(draws out the patterns from data), and outputs what it is. <br><br>\n",
    "\n",
    "- A neural network is composed of layers, which is a collection of neurons, with connections between different layers. These layers transform data by first calculating the weighted sum of inputs and then normalizing it using the activation functions assigned to the neurons.\n",
    "\n",
    "<img src=\"3.png\">\n",
    "\n",
    "- The leftmost layer in a Neural Network is called the input layer, and the rightmost layer is called the output layer. The layers between the input and the output, are called the hidden layers. Any Neural Network has 1 input layer and 1 output layer. \n",
    "\n",
    "- The number of hidden layers differ between different networks depending on the complexity of the problem. Also, each hidden layer can have its own activation function.\n",
    "\n",
    "<br><br>\n",
    "- Here 3 terms Comes in picture 1. Neuron , 2. Weights , 3. Bias , 4. Actiation_Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Like in a human brain, the basic building block of a Neural Network is a Neuron. Its functionality is similar to a human brain, i.e, it takes in some inputs and fires an output. Each neuron is a small computing unit that takes a set of real valued numbers as input, performs some computation on them, and produces a single output value.\n",
    "\n",
    "- The basic unit of computation in a neural network is the neuron, often called as a node or unit. It receives input from some other nodes, or from an external source and computes an output. Each input has an associated weight (w), which is assigned on the basis of its relative importance to other inputs. The node applies a activation function f (defined below) to the weighted sum of its inputs as in figure below.\n",
    "\n",
    "<img src='4.png'>\n",
    "\n",
    "##### The above network have: \n",
    "- numerical inputs X1 and X2 \n",
    "- weights w1 and w2 associated with those inputs\n",
    "- b (called the Bias) associated with it.\n",
    "\n",
    "The Left side Picture is Neuron Of Human Brain ,The Right Side is Artificial Neuron <br>\n",
    "\n",
    "#### Biological Neuron Work:\n",
    "* Information from other neurons, in the form of electrical impulses, enters the <u style=\"color:red\">dendrites</u> at connection points called <u style=\"color:red\">synapses</u>. The information flows from the dendrites to the cell where it is processed. The output signal, a train of impulses, is then sent down the <u style=\"color:red\">axon</u> to the synapse of other neurons. <br><br>\n",
    "\n",
    "#### Artificial Neuron Work:\n",
    "* The arrangements and connections of the neurons made up the network and have three layers. \n",
    "* The first layer is called the <u style=\"color:red\">input layer</u> and is the only layer exposed to external signals.\n",
    "* The input layer transmits signals to the neurons in the next layer, which is called a <u style=\"color:red\">hidden layer</u>. <u style=\"color:red\">The hidden layer extracts relevant features or patterns from the received signals.</u> \n",
    "* Those features or patterns that are considered important are then directed to the <u style=\"color:red\">output layer</u>, which is the final layer of the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"5.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Layers And Multi Layer Netwrok\n",
    "<img src=\"6.png\">\n",
    "\n",
    "- In Multi Layer net there are many number of hidden layer in between input and output layer,but in single only one or not hidden layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight:\n",
    "\n",
    "* Every input(x) to a neuron has an associated weight(w), which is assigned on the basis of its relative importance to other inputs.\n",
    "* The way a neuron works is, if the weighted sum of inputs is greater than a specific threshold, it would give an output 1, otherwise an output 0. This is the mathematical model of a neuron, also known as the Perceptron.\n",
    "* Every neural unit takes in a weighted sum of its inputs, with an additional term in the sum called a Bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias:\n",
    "\n",
    "*  Bias is a constant which is used to adjust the output along with the weighted sum of inputs, so that the model can best fit for the given data.\n",
    "<center><h3> z=w.x+b</h3></center>\n",
    "\n",
    "I defined \n",
    "- weighted sum z \n",
    "- weight vector w\n",
    "- input vector x \n",
    "- bias value b.\n",
    "\n",
    "\n",
    "<center><h3> y=a=f(z)</h3></center>\n",
    "\n",
    "- The output(y) of the neuron is a function f of the weighted sum of inputs z. The function f is non linear and is called the Activation Function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Function: \n",
    "- The purpose of activation function is to introduce non-linearity into the output of neuron. It takes a single number, and performs some mathematical operation on it. There are several activation functions used in practice:\n",
    "\n",
    "    1. Sigmoid\n",
    "    2. Tanh\n",
    "    3. ReLU\n",
    "    4. Leaky relu\n",
    "    5. Softmax function\n",
    "- These Are most widly use activation function that i covered in subsequent notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
