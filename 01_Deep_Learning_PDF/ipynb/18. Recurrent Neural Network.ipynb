{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q. Why do we use an RNN instead of a simple neural network?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use Recurrent Neural Networks mostly in sequential data.We use RNN over standard neural networks due to the following reasons :\n",
    "\n",
    "- In case of sequential data, the inputs and outputs can be of different lengths. For e.g. , in sentiment analysis, we map the input sentences to one number describing the sentiment of the text.\n",
    "- Standard neural network does not share features learnt across different positions of text. For e.g. , in named entity recognition(identifying names of person in sentences), suppose we identify Henry occurs in first position as name, we would want the algorithm to use this information in case Henry occurs later again in the sentence. We want things learnt in one part to generalize in others parts in sequence data.\n",
    "- The parameters required for handling text will be very large in case of Standard neural networks. RNN requires much less parameters to learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Recurrent Neural Network(RNN) are a type of Neural Network where the output from previous step are fed as input to the current step. \n",
    "- In traditional neural networks, all the inputs and outputs are independent of each other, but in cases like when it is required to predict the next word of a sentence, the previous words are required and hence there is a need to remember the previous words.\n",
    "- Thus RNN came into existence, which solved this issue with the help of a Hidden Layer. The main and most important feature of RNN is Hidden state, which remembers some information about a sequence.\n",
    "- RNN have a “memory” which remembers all information about what has been calculated. It uses the same parameters for each input as it performs the same task on all the inputs or hidden layers to produce the output. \n",
    "- This reduces the complexity of parameters, unlike other neural networks.\n",
    "\n",
    "<img src=\"85.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"82.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-to-one:\n",
    "This is also called Plain Neural networks. It deals with a fixed size of the input to the fixed size of output, where they are independent of previous information/output.\n",
    "\n",
    "Example: Image classification.\n",
    "\n",
    "#### One-to-Many:\n",
    "It deals with a fixed size of information as input that gives a sequence of data as output.\n",
    "\n",
    "Example: Image Captioning takes the image as input and outputs a sentence of words.\n",
    "\n",
    "#### Many-to-One:\n",
    "It takes a sequence of information as input and outputs a fixed size of the output.\n",
    "\n",
    "Example: sentiment analysis where any sentence is classified as expressing the positive or negative sentiment.\n",
    "\n",
    "#### Many-to-Many:\n",
    "It takes a Sequence of information as input and processes the recurrently outputs as a Sequence of data.\n",
    "\n",
    "Example: Machine Translation, where the RNN reads any sentence in English and then outputs the sentence in French.\n",
    "\n",
    "#### Bidirectional Many-to-Many:\n",
    "Synced sequence input and output. Notice that in every case are no pre-specified constraints on the lengths sequences because the recurrent transformation (green) is fixed and can be applied as many times as we like.\n",
    "\n",
    "Example: Video classification where we wish to label every frame of the video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"alt\">\n",
    "<tr>\n",
    "\t<th>S.no</th>\n",
    "\t<th>CNN</th>\n",
    "\t<th>RNN</th>\n",
    "</tr>\n",
    "<tr>\n",
    "\t<td><strong>1</strong></td>\n",
    "\t<td><strong>CNN</strong> stands for <strong>Convolutional Neural Network</strong>.</td>\n",
    "\t<td><strong>RNN</strong> stands for <strong>Recurrent Neural Network</strong>.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "\t<td><strong>2</strong></td>\n",
    "\t<td>CNN is considered to be more potent than RNN.</td>\n",
    "\t<td>RNN includes less feature compatibility when compared to CNN.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "\t<td><strong>3</strong></td>\n",
    "\t<td>CNN is ideal for images and video processing.</td>\n",
    "\t<td>RNN is ideal for text and speech Analysis.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "\t<td><strong>4</strong></td>\n",
    "\t<td>It is suitable for spatial data like images.</td>\n",
    "\t<td>RNN is used for temporal data, also called sequential data.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "\t<td><strong>5</strong></td>\n",
    "\t<td>The network takes fixed-size inputs and generates fixed size outputs.</td>\n",
    "\t<td>RNN can handle arbitrary input/ output lengths.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "\t<td><strong>6</strong></td>\n",
    "\t<td>CNN is a type of feed-forward artificial neural network with variations of multilayer perceptron's designed to use minimal amounts of preprocessing.</td>\n",
    "\t<td>RNN, unlike feed-forward neural networks- can use their internal memory to process arbitrary sequences of inputs.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "\t<td><strong>7</strong></td>\n",
    "\t<td>CNN's use of connectivity patterns between the neurons. CNN is affected by the organization of the animal <strong>visual cortex</strong>, whose individual neurons are arranged in such a way that they can respond to overlapping regions in the visual field.</td>\n",
    "\t<td>Recurrent neural networks use time-series information- what a user spoke last would impact what he will speak next.</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
