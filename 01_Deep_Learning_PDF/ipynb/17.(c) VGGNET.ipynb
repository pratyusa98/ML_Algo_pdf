{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16\n",
    "\n",
    "- VGG16 is a convolution neural net (CNN ) architecture which was used to win ILSVR(Imagenet) competition in 2014. \n",
    "- It is considered to be one of the excellent vision model architecture till date. Most unique thing about VGG16 is that instead of having a large number of hyper-parameter they focused on having convolution layers of 3x3 filter with a stride 1 and always used same padding and maxpool layer of 2x2 filter of stride 2. \n",
    "- It follows this arrangement of convolution and max pool layers consistently throughout the whole architecture. In the end it has 2 FC(fully connected layers) followed by a softmax for output. The 16 in VGG16 refers to it has 16 layers that have weights. This network is a pretty large network and it has about 138 million (approx) parameters.\n",
    "\n",
    "\n",
    "<img src=\"80.png\">\n",
    "<img src=\"81.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following are the layers of the model:\n",
    "\n",
    "- Convolutional Layers = 13\n",
    "- Pooling Layers = 5\n",
    "- Dense Layers = 3\n",
    "\n",
    "Let us explore the layers in detail:\n",
    "\n",
    "1. <b>Input:</b> Image of dimensions (224, 224, 3).\n",
    "2. <b>Convolution Layer Conv1:</b>\n",
    "        - Conv1-1: 64 filters\n",
    "        - Conv1-2: 64 filters and Max Pooling\n",
    "        - Image dimensions: (224, 224)\n",
    "3. <b>Convolution layer Conv2: </b> Now, we increase the filters to 128\n",
    "        - Input Image dimensions: (112,112)\n",
    "        - Conv2-1: 128 filters\n",
    "        - Conv2-2: 128 filters and Max Pooling\n",
    "4. <b>Convolution Layer Conv3:</b> Again, double the filters to 256, and now add another convolution layer\n",
    "        - Input Image dimensions: (56,56)\n",
    "        - Conv3-1: 256 filters\n",
    "        - Conv3-2: 256 filters\n",
    "        - Conv3-3: 256 filters and Max Pooling\n",
    "5. <b>Convolution Layer Conv4:</b> Similar to Conv3, but now with 512 filters\n",
    "        - Input Image dimensions: (28, 28)\n",
    "        - Conv4-1: 512 filters\n",
    "        - Conv4-2: 512 filters\n",
    "        - Conv4-3: 512 filters and Max Pooling\n",
    "6. <b>Convolution Layer Conv5:</b> Same as Conv4\n",
    "        - Input Image dimensions: (14, 14)\n",
    "        - Conv5-1: 512 filters\n",
    "        - Conv5-2: 512 filters\n",
    "        - Conv5-3: 512 filters and Max Pooling\n",
    "        - The output dimensions here are (7, 7). At this point, we flatten the output of this layer to generate a feature vector\n",
    "        \n",
    "7. <b>Fully Connected/Dense FC1:</b> 4096 nodes, generating a feature vector of size(1, 4096)\n",
    "8. <b>Fully ConnectedDense FC2:</b> 4096 nodes generating a feature vector of size(1, 4096)\n",
    "9. <b>Fully Connected /Dense FC3:</b> 4096 nodes, generating 1000 channels for 1000 classes. This is then passed on to a Softmax activation function\n",
    "10. <b>Output layer</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">VGG16 contains 16 layers and VGG19 contains 19 layers. A series of VGGs are exactly the same in the last three fully connected layers. The overall structure includes 5 sets of convolutional layers, followed by a MaxPool. The difference is that more and more cascaded convolutional layers are included in the five sets of convolutional layers .\n",
    "\n",
    "![config](img/config2.jpg)\n",
    "\n",
    "\n",
    "> Each convolutional layer in AlexNet contains only one convolution, and the size of the convolution kernel is 7 * 7 ,. In VGGNet, each convolution layer contains 2 to 4 convolution operations. The size of the convolution kernel is 3 * 3, the convolution step size is 1, the pooling kernel is 2 * 2, and the step size is 2. The most obvious improvement of VGGNet is to reduce the size of the convolution kernel and increase the number of convolution layers.\n",
    "\n",
    "\n",
    "![config](img/config3.jpg)\n",
    "\n",
    "\n",
    "> Using multiple convolution layers with smaller convolution kernels instead of a larger convolution layer with convolution kernels can reduce parameters on the one hand, and the author believes that it is equivalent to more non-linear mapping, which increases the Fit expression ability.\n",
    "\n",
    "![config](img/config4.png)\n",
    "\n",
    ">Two consecutive 3 * 3 convolutions are equivalent to a 5 * 5 receptive field, and three are equivalent to 7 * 7. The advantages of using three 3 * 3 convolutions instead of one 7 * 7 convolution are twofold : one, including three ReLu layers instead of one , makes the decision function more discriminative; and two, reducing parameters . For example, the input and output are all C channels. 3 convolutional layers using 3 * 3 require 3 (3 * 3 * C * C) = 27 * C * C, and 1 convolutional layer using 7 * 7 requires 7 * 7 * C * C = 49C * C. This can be seen as applying a kind of regularization to the 7 * 7 convolution, so that it is decomposed into three 3 * 3 convolutions.\n",
    "\n",
    ">The 1 * 1 convolution layer is mainly to increase the non-linearity of the decision function without affecting the receptive field of the convolution layer. Although the 1 * 1 convolution operation is linear, ReLu adds non-linearity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some basic questions\n",
    "\n",
    "**Q1: Why can 3 3x3 convolutions replace 7x7 convolutions?**\n",
    "\n",
    "***Answer 1***\n",
    "\n",
    "3 3x3 convolutions, using 3 non-linear activation functions, increasing non-linear expression capabilities, making the segmentation plane more separable\n",
    "Reduce the number of parameters. For the convolution kernel of C channels, 7x7 contains parameters , and the number of 3 3x3 parameters is greatly reduced.\n",
    "\n",
    "\n",
    "**Q2: The role of 1x1 convolution kernel**\n",
    "\n",
    "***Answer 2***\n",
    "\n",
    "Increase the nonlinearity of the model without affecting the receptive field\n",
    "1x1 winding machine is equivalent to linear transformation, and the non-linear activation function plays a non-linear role\n",
    "\n",
    "\n",
    "**Q3: The effect of network depth on results (in the same year, Google also independently released the network GoogleNet with a depth of 22 layers)**\n",
    "\n",
    "***Answer 3***\n",
    "\n",
    "VGG and GoogleNet models are deep\n",
    "Small convolution\n",
    "VGG only uses 3x3, while GoogleNet uses 1x1, 3x3, 5x5, the model is more complicated (the model began to use a large convolution kernel to reduce the calculation of the subsequent machine layer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement On Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing library\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D,MaxPool2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "model.add(Dense(units=2, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output of this will be the summary of the model which I just created.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 8194      \n",
      "=================================================================\n",
      "Total params: 134,268,738\n",
      "Trainable params: 134,268,738\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"The output of this will be the summary of the model which I just created.\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I have started with initialising the model by specifying that the model is a sequential model. After initialising the model I add\n",
    "\n",
    "→ 2 x convolution layer of 64 channel of 3x3 kernal and same padding\n",
    "\n",
    "→ 1 x maxpool layer of 2x2 pool size and stride 2x2\n",
    "\n",
    "→ 2 x convolution layer of 128 channel of 3x3 kernal and same padding\n",
    "\n",
    "→ 1 x maxpool layer of 2x2 pool size and stride 2x2\n",
    "\n",
    "→ 3 x convolution layer of 256 channel of 3x3 kernal and same padding\n",
    "\n",
    "→ 1 x maxpool layer of 2x2 pool size and stride 2x2\n",
    "\n",
    "→ 3 x convolution layer of 512 channel of 3x3 kernal and same padding\n",
    "\n",
    "→ 1 x maxpool layer of 2x2 pool size and stride 2x2\n",
    "\n",
    "→ 3 x convolution layer of 512 channel of 3x3 kernal and same padding\n",
    "\n",
    "→ 1 x maxpool layer of 2x2 pool size and stride 2x2\n",
    "\n",
    "I also add relu(Rectified Linear Unit) activation to each layers so that all the negative values are not passed to the next layer.\n",
    "\n",
    "After creating all the convolution I pass the data to the dense layer so for that I flatten the vector which comes out of the convolutions and add\n",
    "\n",
    "→ 1 x Dense layer of 4096 units\n",
    "\n",
    "→ 1 x Dense layer of 4096 units\n",
    "\n",
    "→ 1 x Dense Softmax layer of 2 units\n",
    "\n",
    "I will use RELU activation for both the dense layer of 4096 units so that I stop forwarding negative values through the network. I use a 2 unit dense layer in the end with softmax activation as I have 2 classes to predict from in the end which are dog and cat. The softmax layer will output the value between 0 and 1 based on the confidence of the model that which class the images belongs to.\n",
    "\n",
    "After the creation of softmax layer the model is finally prepared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
