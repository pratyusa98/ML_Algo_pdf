{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALEXNET\n",
    "\n",
    "#### The most important features of the AlexNet paper are:\n",
    "\n",
    "- As the model had to train 60 million parameters (which is quite a lot), it was prone to overfitting. According to the paper, the usage of Dropout and Data Augmentation significantly helped in reducing overfitting. The first and second fully connected layers in the architecture thus used a dropout of 0.5 for the purpose. Artificially increasing the number of images through data augmentation helped in the expansion of the dataset dynamically during runtime, which helped the model generalize better.\n",
    "\n",
    "- Another distinct factor was using the ReLU activation function instead of tanh or sigmoid, which resulted in faster training times (a decrease in training time by 6 times). Deep Learning Networks usually employ ReLU non-linearity to achieve faster training times as the others start saturating when they hit higher activation values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- AlexNet is a Classic type of Convolutional Neural Network, and it came into existence after the 2012 ImageNet challenge. The network architecture is given below :\n",
    "<img src=\"78.png\">\n",
    "\n",
    "<img src=\"79.png\">\n",
    "\n",
    "### Model Explanation : \n",
    "- The Input to this model have the dimensions 227x227x3 follwed by a Convolutional Layer with 96 filters of 11x11 dimensions and having a ‘same’ padding and a stride of 4. The resulting output dimensions are given as :\n",
    "\n",
    "              floor(((n + 2*padding - filter)/stride) + 1 ) * floor(((n + 2*padding — filter)/stride) + 1)\n",
    "\n",
    "##### Note : This formula is for square input with height = width = n\n",
    "\n",
    "- Explaining the first Layer with input 227x227x3 and Convolutional layer with 96 filters of 11x11 , ‘valid’ padding and stride = 4 , output dims will be\n",
    "\n",
    "= floor(((227 + 0–11)/4) + 1) * floor(((227 + 0–11)/4) + 1)\n",
    "\n",
    "= floor((216/4) + 1) * floor((216/4) + 1)\n",
    "\n",
    "= floor(54 + 1) * floor(54 + 1)\n",
    "\n",
    "= 55 * 55\n",
    "\n",
    "- Since number of filters = 96 , thus output of first Layer is : 55x55x96\n",
    "- Continuing we have the MaxPooling layer (3, 3) with the stride of 2,making the output size decrease to 27x27x96, followed by another Convolutional Layer with 256, (5,5) filters and ‘same’ padding, that is, the output height and width are retained as the previous layer thus output from this layer is 27x27x256. \n",
    "- Next we have the MaxPooling again ,reducing the size to 13x13x256. Another Convolutional Operation with 384, (3,3) filters having same padding is applied twice giving the output as 13x13x384, followed by another Convulutional Layer with 256 , (3,3) filters and same padding resulting in 13x13x256 output. \n",
    "- This is MaxPooled and dimensions are reduced to 6x6x256. Further the layer is Flatten out and 2 Fully Connected Layers with 4096 units each are made which is further connected to 1000 units softmax layer.\n",
    "\n",
    "- The network is used for classifying much large number of classes as per our requirement. However in our case, we will make the output softmax layer with 6 units as we ahve to classify into 6 classes. The softmax layer gives us the probablities for each class to which an Input Image might belong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing library\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() \n",
    "\n",
    "# 1st Convolutional Layer \n",
    "model.add(Conv2D(filters = 96, input_shape = (224, 224, 3), kernel_size = (11, 11), strides = (4, 4), padding = 'valid')) \n",
    "model.add(Activation('relu')) \n",
    "# Max-Pooling \n",
    "model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'valid')) \n",
    "# Batch Normalisation \n",
    "model.add(BatchNormalization()) \n",
    "\n",
    "# 2nd Convolutional Layer \n",
    "model.add(Conv2D(filters = 256, kernel_size = (11, 11), strides = (1, 1), padding = 'valid')) \n",
    "model.add(Activation('relu')) \n",
    "# Max-Pooling \n",
    "model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'valid')) \n",
    "# Batch Normalisation \n",
    "model.add(BatchNormalization()) \n",
    "\n",
    "# 3rd Convolutional Layer \n",
    "model.add(Conv2D(filters = 384, kernel_size = (3, 3), strides = (1, 1), padding = 'valid')) \n",
    "model.add(Activation('relu')) \n",
    "# Batch Normalisation \n",
    "model.add(BatchNormalization()) \n",
    "\n",
    "# 4th Convolutional Layer \n",
    "model.add(Conv2D(filters = 384, kernel_size = (3, 3), strides = (1, 1), padding = 'valid')) \n",
    "model.add(Activation('relu')) \n",
    "# Batch Normalisation \n",
    "model.add(BatchNormalization()) \n",
    "\n",
    "# 5th Convolutional Layer \n",
    "model.add(Conv2D(filters = 256, kernel_size = (3, 3), strides = (1, 1), padding = 'valid')) \n",
    "model.add(Activation('relu')) \n",
    "# Max-Pooling \n",
    "model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2),padding = 'valid')) \n",
    "# Batch Normalisation \n",
    "model.add(BatchNormalization()) \n",
    "\n",
    "# Flattening \n",
    "model.add(Flatten()) \n",
    "\n",
    "# 1st Dense Layer \n",
    "model.add(Dense(4096, input_shape = (224*224*3, ))) \n",
    "model.add(Activation('relu')) \n",
    "# Add Dropout to prevent overfitting \n",
    "model.add(Dropout(0.4)) \n",
    "# Batch Normalisation \n",
    "model.add(BatchNormalization()) \n",
    "\n",
    "# 2nd Dense Layer \n",
    "model.add(Dense(4096)) \n",
    "model.add(Activation('relu')) \n",
    "# Add Dropout \n",
    "model.add(Dropout(0.4)) \n",
    "# Batch Normalisation \n",
    "model.add(BatchNormalization()) \n",
    "\n",
    "# Output Softmax Layer \n",
    "model.add(Dense(10)) \n",
    "model.add(Activation('softmax')) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 54, 54, 96)        34944     \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 54, 54, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 27, 27, 96)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 27, 27, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 17, 17, 256)       2973952   \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 6, 6, 384)         885120    \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 6, 6, 384)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 6, 6, 384)         1536      \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 4, 4, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 4, 4, 384)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 4, 4, 384)         1536      \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 2, 2, 256)         884992    \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 1, 1, 256)         1024      \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 4096)              1052672   \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                40970     \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 24,019,722\n",
      "Trainable params: 24,000,586\n",
      "Non-trainable params: 19,136\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Model Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
