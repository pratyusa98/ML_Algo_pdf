{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional neural networks (CNN) \n",
    "\n",
    "- Cnn are one of the most popular models used today. This neural network computational model uses a variation of multilayer perceptrons and contains one or more convolutional layers that can be either entirely connected or pooled. \n",
    "- These convolutional layers create feature maps that record a region of image which is ultimately broken into rectangles and sent out for nonlinear processing.\n",
    "\n",
    "<img src=\"3.jpeg\">\n",
    "\n",
    "- Let us suppose this in the input matrix of 5×5 and a filter of matrix 3X3, for those who don’t know what a filter is a set of weights in a matrix applied on an image or a matrix to obtain the required features, please search on convolution if this is your first time!\n",
    "\n",
    "#### Note: We always take the sum or average of all the values while doing a convolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps Involve in CNN\n",
    "<img src=\"64.png\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Edge Detection (Convolution)\n",
    "- In the previous article, we saw that the early layers of a neural network detect edges from an image. Deeper layers might be able to detect the cause of the objects and even more deeper layers might detect the cause of complete objects (like a person’s face).\n",
    "\n",
    "In this section, we will focus on how the edges can be detected from an image. Suppose we are given the below image: As you can see, there are many vertical and horizontal edges in the image. The first thing to do is to detect these edges:\n",
    "\n",
    "<img src=\"63.png\">\n",
    "\n",
    "<img src=\"66.png\">\n",
    "\n",
    "- So, we take the first 3 X 3 matrix from the 6 X 6 image and multiply it with the filter. Now, the first element of the 4 X 4 output will be the sum of the element-wise product of these values, i.e. 0*0+0*0+1*0+1*0+0*1+0*0+0*0+1*0+1*0 =0. To calculate the second element of the 4 X 4 output, we will shift our filter one step towards the right and again get the sum of the element-wise product:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pooling\n",
    "\n",
    "- A pooling layer is another building block of a CNN. Its function is to progressively reduce the spatial size of the representation to reduce the amount of parameters and computation in the network. Pooling layer operates on each feature map independently. The most common approach used in pooling is max pooling.\n",
    "\n",
    "#### Types of Pooling Layers :- \n",
    "    1. Max Pooling\n",
    "Max pooling is a pooling operation that selects the maximum element from the region of the feature map covered by the filter. Thus, the output after max-pooling layer would be a feature map containing the most prominent features of the previous feature map.\n",
    "<img src=\"68.png\" style=\"height:200px\">\n",
    "\n",
    "    2. Average Pooling\n",
    "Average pooling computes the average of the elements present in the region of feature map covered by the filter. Thus, while max pooling gives the most prominent feature in a particular patch of the feature map, average pooling gives the average of features present in a patch.\n",
    "<img src=\"69.png\" style=\"height:200px\">\n",
    "\n",
    "- More On Pooling https://www.geeksforgeeks.org/cnn-introduction-to-pooling-layer/\n",
    "\n",
    "#### Now Apply Pooling in our above Feature Map\n",
    "\n",
    "<img src=\"67.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem with Simple Convolution Layers\n",
    "\n",
    "- While applying convolutions we will not obtain the output dimensions the same as input we will lose data over borders so we append a border of zeros and recalculate the convolution covering all the input values.\n",
    "\n",
    "        1. Padding\n",
    "        2. Striding\n",
    "\n",
    "### 1. Padding\n",
    "\n",
    "<img src=\"72.png\">\n",
    "\n",
    "* See In without padding our input is 6x6 but output image goes down into 4x4 . so by using padding we got the same result.Padding is simply a process of adding layers of zeros to our input images so as to avoid the problems mentioned above.\n",
    "\n",
    "<img src=\"73.png\" style=\"height:250px\">\n",
    "* So padding  prevents shrinking as, if p = number of layers of zeros added to the border of the image, then our (n x n) image becomes (n + 2p) x (n + 2p) image after padding. So, applying convolution-operation (with (f x f) filter) outputs (n + 2p – f + 1) x (n + 2p – f + 1) images. For example, adding one layer of padding to an (8 x 8) image and using a (3 x 3) filter we would get an (8 x 8) output after performing convolution operation.\n",
    "\n",
    "<img src=\"4.gif\" style=\"height:300px\">\n",
    "\n",
    "### 2. Strides\n",
    "\n",
    "- It uses to reduce the size of matrix. if we sfited by 1 then we called stride=1 and if we sfited by 2 means stride = 2 so on.\n",
    "\n",
    "<img src=\"75.png\">\n",
    "\n",
    "<img src=\"5.gif\" style=\"height:300px\">\n",
    "\n",
    "### Padding,Stride Put in One Equation\n",
    "<img src=\"76.png\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3 : Flattening\n",
    "\n",
    "- Flattening is converting the data into a 1-dimensional array for inputting it to the next layer. We flatten the output of the convolutional layers to create a single long feature vector. And it is connected to the final classification model, which is called a fully-connected layer.\n",
    "\n",
    "<img src=\"70.png\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4\n",
    "### Complete CNN in one View\n",
    "\n",
    "#### here in last step we use full connection network\n",
    "<img src=\"71.png\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
