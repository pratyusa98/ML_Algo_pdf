{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16\n",
    "\n",
    "- VGG16 is a convolution neural net (CNN ) architecture which was used to win ILSVR(Imagenet) competition in 2014. \n",
    "- It is considered to be one of the excellent vision model architecture till date. Most unique thing about VGG16 is that instead of having a large number of hyper-parameter they focused on having convolution layers of 3x3 filter with a stride 1 and always used same padding and maxpool layer of 2x2 filter of stride 2. \n",
    "- It follows this arrangement of convolution and max pool layers consistently throughout the whole architecture. In the end it has 2 FC(fully connected layers) followed by a softmax for output. The 16 in VGG16 refers to it has 16 layers that have weights. This network is a pretty large network and it has about 138 million (approx) parameters.\n",
    "\n",
    "\n",
    "<img src=\"80.png\">\n",
    "<img src=\"81.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following are the layers of the model:\n",
    "\n",
    "- Convolutional Layers = 13\n",
    "- Pooling Layers = 5\n",
    "- Dense Layers = 3\n",
    "\n",
    "Let us explore the layers in detail:\n",
    "\n",
    "1. <b>Input:</b> Image of dimensions (224, 224, 3).\n",
    "2. <b>Convolution Layer Conv1:</b>\n",
    "        - Conv1-1: 64 filters\n",
    "        - Conv1-2: 64 filters and Max Pooling\n",
    "        - Image dimensions: (224, 224)\n",
    "3. <b>Convolution layer Conv2: </b> Now, we increase the filters to 128\n",
    "        - Input Image dimensions: (112,112)\n",
    "        - Conv2-1: 128 filters\n",
    "        - Conv2-2: 128 filters and Max Pooling\n",
    "4. <b>Convolution Layer Conv3:</b> Again, double the filters to 256, and now add another convolution layer\n",
    "        - Input Image dimensions: (56,56)\n",
    "        - Conv3-1: 256 filters\n",
    "        - Conv3-2: 256 filters\n",
    "        - Conv3-3: 256 filters and Max Pooling\n",
    "5. <b>Convolution Layer Conv4:</b> Similar to Conv3, but now with 512 filters\n",
    "        - Input Image dimensions: (28, 28)\n",
    "        - Conv4-1: 512 filters\n",
    "        - Conv4-2: 512 filters\n",
    "        - Conv4-3: 512 filters and Max Pooling\n",
    "6. <b>Convolution Layer Conv5:</b> Same as Conv4\n",
    "        - Input Image dimensions: (14, 14)\n",
    "        - Conv5-1: 512 filters\n",
    "        - Conv5-2: 512 filters\n",
    "        - Conv5-3: 512 filters and Max Pooling\n",
    "        - The output dimensions here are (7, 7). At this point, we flatten the output of this layer to generate a feature vector\n",
    "        \n",
    "7. <b>Fully Connected/Dense FC1:</b> 4096 nodes, generating a feature vector of size(1, 4096)\n",
    "8. <b>Fully ConnectedDense FC2:</b> 4096 nodes generating a feature vector of size(1, 4096)\n",
    "9. <b>Fully Connected /Dense FC3:</b> 4096 nodes, generating 1000 channels for 1000 classes. This is then passed on to a Softmax activation function\n",
    "10. <b>Output layer</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement On Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing library\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D,MaxPool2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "model.add(Dense(units=2, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output of this will be the summary of the model which I just created.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 8194      \n",
      "=================================================================\n",
      "Total params: 134,268,738\n",
      "Trainable params: 134,268,738\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"The output of this will be the summary of the model which I just created.\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I have started with initialising the model by specifying that the model is a sequential model. After initialising the model I add\n",
    "\n",
    "→ 2 x convolution layer of 64 channel of 3x3 kernal and same padding\n",
    "\n",
    "→ 1 x maxpool layer of 2x2 pool size and stride 2x2\n",
    "\n",
    "→ 2 x convolution layer of 128 channel of 3x3 kernal and same padding\n",
    "\n",
    "→ 1 x maxpool layer of 2x2 pool size and stride 2x2\n",
    "\n",
    "→ 3 x convolution layer of 256 channel of 3x3 kernal and same padding\n",
    "\n",
    "→ 1 x maxpool layer of 2x2 pool size and stride 2x2\n",
    "\n",
    "→ 3 x convolution layer of 512 channel of 3x3 kernal and same padding\n",
    "\n",
    "→ 1 x maxpool layer of 2x2 pool size and stride 2x2\n",
    "\n",
    "→ 3 x convolution layer of 512 channel of 3x3 kernal and same padding\n",
    "\n",
    "→ 1 x maxpool layer of 2x2 pool size and stride 2x2\n",
    "\n",
    "I also add relu(Rectified Linear Unit) activation to each layers so that all the negative values are not passed to the next layer.\n",
    "\n",
    "After creating all the convolution I pass the data to the dense layer so for that I flatten the vector which comes out of the convolutions and add\n",
    "\n",
    "→ 1 x Dense layer of 4096 units\n",
    "\n",
    "→ 1 x Dense layer of 4096 units\n",
    "\n",
    "→ 1 x Dense Softmax layer of 2 units\n",
    "\n",
    "I will use RELU activation for both the dense layer of 4096 units so that I stop forwarding negative values through the network. I use a 2 unit dense layer in the end with softmax activation as I have 2 classes to predict from in the end which are dog and cat. The softmax layer will output the value between 0 and 1 based on the confidence of the model that which class the images belongs to.\n",
    "\n",
    "After the creation of softmax layer the model is finally prepared."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
